# [Final Project Proposal: Interview Helper System with AI and Emotion Analysis (JobAId)](https://github.com/ReyadGH/capstone)


## Introduction
This document serves as the proposal for our final project in the Data Science Bootcamp. The project, titled "Interview Helper System with AI and Emotion Analysis," aims to address the challenge of improving interview evaluations by analyzing facial expressions and emotions. This project is chosen due to its potential impact on the recruitment industry and its alignment with our career goals.

## Background
The recruitment industry faces challenges in assessing candidates' non-verbal cues and emotions during interviews. The problem of subjective interview evaluations affects both employers and job seekers. Solving this problem will provide benefits such as more objective hiring decisions, improved interview preparation, and enhanced candidate experience.

## Project Objectives
- To develop an AI-based system that can detect facial landmarks and predict emotions during interviews.
- To integrate audio processing to transcribe and analyze speech content.
- To create a user-friendly interface for users to practice mock interviews and receive feedback.

## Data Sources
The primary dataset for this project will be sourced from publicly available datasets of facial expressions and emotions. These datasets are chosen for their comprehensiveness and reliability. Preliminary preprocessing will include data cleaning, normalization, and augmentation.

## Methodology
### Data Cleaning and Preprocessing
- **Analytical techniques**: Standardizing and normalizing data, handling missing values.
- **Used tools**: Utilizing Python libraries such as Pandas, NumPy, and OpenCV.

### Model Development
- **Analytical techniques**: Facial landmark detection using MediaPipe, emotion prediction using convolutional neural networks (CNNs).
- **Used tools**: Applying machine learning algorithms with TensorFlow, Keras, and MediaPipe to develop the predictive model.

### Validation and Testing
- **Analytical techniques**: Cross-validation and performance metrics evaluation.
- **Used tools**: Using cross-validation techniques and Scikit-learn for model validation and evaluation.

## Results
By the conclusion of this project, I expect to develop a system that accurately detects facial landmarks and predicts emotions with high precision. Additionally, the audio analysis component will provide meaningful insights into the interviewee's responses.

## Conclusion
In conclusion, the "Interview Helper System with AI and Emotion Analysis" aims to leverage data science techniques to address the challenges in the recruitment process. This project is expected to yield significant benefits by improving interview evaluations and providing valuable feedback to candidates. I am excited about the potential impacts of this project and look forward to exploring its various aspects.

## Future Improvements:
- Enhance the system with more advanced emotion recognition models.
- Integrate a more comprehensive set of interview questions and scenarios.
- Develop a mobile application for wider accessibility.

## Contact Information
For further communication, please contact:

**Group Members:**
- Riyadh Alghamdi [Github](https://github.com/ReyadGH) | [Linkedin](https://www.linkedin.com/in/riyadh-alghamdi-78313a252/)
- Omar Alhuwaishel [Github](https://github.com/Omar-Alhuwaishel) | [Linkedin](https://www.linkedin.com/in/omar-alhuwaishel/)
- Tariq Abuwashtan [Github](https://github.com/TariqWashtan) | [Linkedin](https://www.linkedin.com/in/tariq-abuwashtan-4307862a0/)

---

## Code Implementation

### Dependencies
- OpenCV
- MediaPipe
- SKlearn
- NumPy
- Deepgram

### Framworks
- FastAPI
- Next.js
- React
