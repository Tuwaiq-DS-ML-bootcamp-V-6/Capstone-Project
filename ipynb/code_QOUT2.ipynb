{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-12T17:08:09.642232Z",
     "start_time": "2024-06-12T17:08:09.417283Z"
    }
   },
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from PIL import Image\n"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T17:09:06.597076Z",
     "start_time": "2024-06-12T17:08:58.809392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "class InstagramPhotoMatcher:\n",
    "    def __init__(self, data_path, origin_df):\n",
    "        self.data_path = data_path\n",
    "        self.origin_df = origin_df\n",
    "        self.train_files = os.listdir(data_path)\n",
    "        self.df_matching = self.create_matching_dataframe()\n",
    "        \n",
    "        self.processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\n",
    "        self.model = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\")\n",
    "        \n",
    "        self.collection_name = 'instagram_data_new'\n",
    "        self.collection = qdrant_client.create_collection(\n",
    "            collection_name=self.collection_name,\n",
    "            vectors_config=VectorParams(\n",
    "                size=1000,\n",
    "                distance=Distance.COSINE\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def create_matching_dataframe(self):\n",
    "        matching = []\n",
    "        for i in range(len(self.origin_df)):\n",
    "            post_date = self.origin_df['post_date'][i]\n",
    "            for file in self.train_files:\n",
    "                if file.endswith('.jpg') and post_date == file[:19]:\n",
    "                    image_path = os.path.join(self.data_path, file)\n",
    "                    instagram_user = self.origin_df['username'][i]\n",
    "                    full_name = self.origin_df['full_name'][i]\n",
    "                    bio = self.origin_df['biography'][i]\n",
    "                    caption = self.origin_df['post_caption'][i]\n",
    "                    link = self.origin_df['post_url'][i]\n",
    "                    matching.append({\n",
    "                        'instagram_user': instagram_user,\n",
    "                        'image_path': image_path.replace(\"\\\\\", '/'),\n",
    "                        'link': link,\n",
    "                        'full_name': full_name,\n",
    "                        'class': 0,\n",
    "                        'bio': bio,\n",
    "                        'caption': caption,\n",
    "                    })\n",
    "        return pd.DataFrame(matching)\n",
    "    \n",
    "    def resize_image(self, image, target_width=256):\n",
    "        image_aspect_ratio = image.size[0] / image.size[1]\n",
    "        resized_img = image.resize(\n",
    "            [target_width, math.floor(target_width * image_aspect_ratio)]\n",
    "        )\n",
    "        return resized_img\n",
    "\n",
    "    def convert_image_to_base64(self, image):\n",
    "        buffered = BytesIO()\n",
    "        image.save(buffered, format=\"JPEG\")\n",
    "        return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "    def upload_item(self, idx):\n",
    "        if idx >= len(self.df_matching):\n",
    "            raise IndexError(\"Index out of range\")\n",
    "        \n",
    "        item_data = self.__getitem__(idx)\n",
    "        row = item_data['row']\n",
    "        encoded_image = item_data['encoded_image']\n",
    "        logits = item_data['logits']\n",
    "    \n",
    "        bio = row['bio'][:512] if isinstance(row['bio'], str) else ''\n",
    "        \n",
    "        points = [\n",
    "            PointStruct(\n",
    "                id=idx,\n",
    "                payload={\n",
    "                    'instagram_user': row['instagram_user'],\n",
    "                    'image_path': row['image_path'],\n",
    "                    'link': row['link'],\n",
    "                    'full_name': row['full_name'],\n",
    "                    'bio': bio,\n",
    "                    'class': row['class'],\n",
    "                    'encoded_image': encoded_image,\n",
    "                },\n",
    "                vector=logits.flatten().tolist()\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        print(qdrant_client.upsert(\n",
    "            collection_name=self.collection_name,\n",
    "            points=points\n",
    "        ))\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self.df_matching):\n",
    "            raise IndexError(\"Index out of range\")\n",
    "        \n",
    "        row = self.df_matching.iloc[idx]\n",
    "        image = Image.open(row['image_path'])\n",
    "        image = image.convert('RGB')\n",
    "        image = self.resize_image(image)\n",
    "        encoded_image = self.convert_image_to_base64(image)\n",
    "        \n",
    "        inputs = self.processor(images=image, return_tensors=\"pt\")\n",
    "        outputs = self.model(**inputs)\n",
    "        \n",
    "        return {\n",
    "            'row': row.to_dict(),\n",
    "            'image': image,\n",
    "            'encoded_image': encoded_image,\n",
    "            'logits': outputs.logits\n",
    "        }\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df_matching)\n",
    "        \n",
    "data_path = '../Data/instagram_photo'\n",
    "df_origin = pd.read_excel('../Data/instagram_posts.xlsx')\n",
    "df_origin['post_date'] = df_origin['post_date'].dt.strftime('%Y-%m-%d_%H-%M-%S')\n",
    "matcher = InstagramPhotoMatcher(data_path, df_origin)"
   ],
   "id": "ef61d7ececa1a282",
   "outputs": [
    {
     "ename": "UnexpectedResponse",
     "evalue": "Unexpected Response: 409 (Conflict)\nRaw response content:\nb'{\"status\":{\"error\":\"Wrong input: Collection `instagram_data_new` already exists!\"},\"time\":0.024640666}'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUnexpectedResponse\u001B[0m                        Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 117\u001B[0m\n\u001B[0;32m    115\u001B[0m df_origin \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_excel(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../Data/instagram_posts.xlsx\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    116\u001B[0m df_origin[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpost_date\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m df_origin[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpost_date\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mdt\u001B[38;5;241m.\u001B[39mstrftime(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mY-\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mm-\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mH-\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mM-\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mS\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m--> 117\u001B[0m matcher \u001B[38;5;241m=\u001B[39m \u001B[43mInstagramPhotoMatcher\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdf_origin\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[14], line 14\u001B[0m, in \u001B[0;36mInstagramPhotoMatcher.__init__\u001B[1;34m(self, data_path, origin_df)\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m ResNetForImageClassification\u001B[38;5;241m.\u001B[39mfrom_pretrained(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmicrosoft/resnet-50\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcollection_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minstagram_data_new\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m---> 14\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcollection \u001B[38;5;241m=\u001B[39m \u001B[43mqdrant_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_collection\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcollection_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollection_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvectors_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mVectorParams\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[43m        \u001B[49m\u001B[43msize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1000\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     18\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdistance\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mDistance\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCOSINE\u001B[49m\n\u001B[0;32m     19\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\Pytorch\\Lib\\site-packages\\qdrant_client\\qdrant_client.py:1730\u001B[0m, in \u001B[0;36mQdrantClient.create_collection\u001B[1;34m(self, collection_name, vectors_config, sparse_vectors_config, shard_number, sharding_method, replication_factor, write_consistency_factor, on_disk_payload, hnsw_config, optimizers_config, wal_config, quantization_config, init_from, timeout, **kwargs)\u001B[0m\n\u001B[0;32m   1681\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Create empty collection with given parameters\u001B[39;00m\n\u001B[0;32m   1682\u001B[0m \n\u001B[0;32m   1683\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1726\u001B[0m \u001B[38;5;124;03m    Operation result\u001B[39;00m\n\u001B[0;32m   1727\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1728\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(kwargs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnknown arguments: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlist\u001B[39m(kwargs\u001B[38;5;241m.\u001B[39mkeys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1730\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_collection\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1731\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcollection_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollection_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1732\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvectors_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvectors_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1733\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshard_number\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshard_number\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1734\u001B[0m \u001B[43m    \u001B[49m\u001B[43msharding_method\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msharding_method\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1735\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreplication_factor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreplication_factor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1736\u001B[0m \u001B[43m    \u001B[49m\u001B[43mwrite_consistency_factor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwrite_consistency_factor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1737\u001B[0m \u001B[43m    \u001B[49m\u001B[43mon_disk_payload\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mon_disk_payload\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1738\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhnsw_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhnsw_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1739\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptimizers_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizers_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1740\u001B[0m \u001B[43m    \u001B[49m\u001B[43mwal_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwal_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1741\u001B[0m \u001B[43m    \u001B[49m\u001B[43mquantization_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquantization_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1742\u001B[0m \u001B[43m    \u001B[49m\u001B[43minit_from\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minit_from\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1743\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1744\u001B[0m \u001B[43m    \u001B[49m\u001B[43msparse_vectors_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msparse_vectors_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1745\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1746\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\Pytorch\\Lib\\site-packages\\qdrant_client\\qdrant_remote.py:2261\u001B[0m, in \u001B[0;36mQdrantRemote.create_collection\u001B[1;34m(self, collection_name, vectors_config, shard_number, replication_factor, write_consistency_factor, on_disk_payload, hnsw_config, optimizers_config, wal_config, quantization_config, init_from, timeout, sparse_vectors_config, sharding_method, **kwargs)\u001B[0m\n\u001B[0;32m   2244\u001B[0m     init_from \u001B[38;5;241m=\u001B[39m GrpcToRest\u001B[38;5;241m.\u001B[39mconvert_init_from(init_from)\n\u001B[0;32m   2246\u001B[0m create_collection_request \u001B[38;5;241m=\u001B[39m models\u001B[38;5;241m.\u001B[39mCreateCollection(\n\u001B[0;32m   2247\u001B[0m     vectors\u001B[38;5;241m=\u001B[39mvectors_config,\n\u001B[0;32m   2248\u001B[0m     shard_number\u001B[38;5;241m=\u001B[39mshard_number,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2258\u001B[0m     sharding_method\u001B[38;5;241m=\u001B[39msharding_method,\n\u001B[0;32m   2259\u001B[0m )\n\u001B[1;32m-> 2261\u001B[0m result: Optional[\u001B[38;5;28mbool\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhttp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollections_api\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_collection\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2262\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcollection_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollection_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2263\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_collection\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcreate_collection_request\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2264\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2265\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mresult\n\u001B[0;32m   2267\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreate collection returned None\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2268\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32m~\\.conda\\envs\\Pytorch\\Lib\\site-packages\\qdrant_client\\http\\api\\collections_api.py:1170\u001B[0m, in \u001B[0;36mSyncCollectionsApi.create_collection\u001B[1;34m(self, collection_name, timeout, create_collection)\u001B[0m\n\u001B[0;32m   1161\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate_collection\u001B[39m(\n\u001B[0;32m   1162\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   1163\u001B[0m     collection_name: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m   1164\u001B[0m     timeout: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1165\u001B[0m     create_collection: m\u001B[38;5;241m.\u001B[39mCreateCollection \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1166\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m m\u001B[38;5;241m.\u001B[39mInlineResponse200:\n\u001B[0;32m   1167\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1168\u001B[0m \u001B[38;5;124;03m    Create new collection with given parameters\u001B[39;00m\n\u001B[0;32m   1169\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1170\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_build_for_create_collection\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1171\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcollection_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollection_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1172\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1173\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcreate_collection\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcreate_collection\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1174\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\Pytorch\\Lib\\site-packages\\qdrant_client\\http\\api\\collections_api.py:116\u001B[0m, in \u001B[0;36m_CollectionsApi._build_for_create_collection\u001B[1;34m(self, collection_name, timeout, create_collection)\u001B[0m\n\u001B[0;32m    114\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mContent-Type\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m headers:\n\u001B[0;32m    115\u001B[0m     headers[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mContent-Type\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mapplication/json\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 116\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapi_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    117\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtype_\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mInlineResponse200\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    118\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mPUT\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    119\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/collections/\u001B[39;49m\u001B[38;5;132;43;01m{collection_name}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    120\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    121\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpath_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    122\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquery_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    123\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcontent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    124\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\Pytorch\\Lib\\site-packages\\qdrant_client\\http\\api_client.py:76\u001B[0m, in \u001B[0;36mApiClient.request\u001B[1;34m(self, type_, method, url, path_params, **kwargs)\u001B[0m\n\u001B[0;32m     74\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparams\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m     75\u001B[0m request \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_client\u001B[38;5;241m.\u001B[39mbuild_request(method, url, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m---> 76\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtype_\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\Pytorch\\Lib\\site-packages\\qdrant_client\\http\\api_client.py:99\u001B[0m, in \u001B[0;36mApiClient.send\u001B[1;34m(self, request, type_)\u001B[0m\n\u001B[0;32m     97\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m ValidationError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     98\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ResponseHandlingException(e)\n\u001B[1;32m---> 99\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m UnexpectedResponse\u001B[38;5;241m.\u001B[39mfor_response(response)\n",
      "\u001B[1;31mUnexpectedResponse\u001B[0m: Unexpected Response: 409 (Conflict)\nRaw response content:\nb'{\"status\":{\"error\":\"Wrong input: Collection `instagram_data_new` already exists!\"},\"time\":0.024640666}'"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T16:55:07.824780Z",
     "start_time": "2024-06-12T16:55:07.819777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "landmarks = [\n",
    "    {\"name\": \"Al Faisaliah Tower\", \"location\": \"Riyadh, Saudi Arabia\"},\n",
    "    {\"name\": \"Al Masmak Palace\", \"location\": \"Riyadh, Saudi Arabia\"},\n",
    "    {\"name\": \"Al Rahmah Mosque\", \"location\": \"Jeddah, Saudi Arabia\"},\n",
    "    {\"name\": \"Diriyah\", \"location\": \"Riyadh, Saudi Arabia\"},\n",
    "    {\"name\": \"Hegra (also known as Al-Hijr or Madain Salih)\", \"location\": \"AlUla, Saudi Arabia\"},\n",
    "    {\"name\": \"Ibrahim Palace\", \"location\": \"Al-Hofuf, Al-Ahsa, Saudi Arabia\"},\n",
    "    {\"name\": \"Ithra (King Abdulaziz Center for World Culture)\", \"location\": \"Dhahran, Saudi Arabia\"},\n",
    "    {\"name\": \"Jabal AlFil (Elephant Rock)\", \"location\": \"AlUla, Saudi Arabia\"},\n",
    "    {\"name\": \"King Abdullah Financial District (KAFD)\", \"location\": \"Riyadh, Saudi Arabia\"},\n",
    "    {\"name\": \"Kingdom Tower (also known as Burj Al Mamlaka)\", \"location\": \"Riyadh, Saudi Arabia\"},\n",
    "    {\"name\": \"Maraya\", \"location\": \"AlUla, Saudi Arabia\"},\n",
    "    {\"name\": \"Nassif House Museum\", \"location\": \"Jeddah, Saudi Arabia\"},\n",
    "    {\"name\": \"Quba Mosque\", \"location\": \"Medina, Saudi Arabia\"},\n",
    "    {\"name\": \"Riyadh Water Tower\", \"location\": \"Riyadh, Saudi Arabia\"},\n",
    "    {\"name\": \"The Clock Towers (also known as Abraj Al Bait)\", \"location\": \"Mecca, Saudi Arabia\"},\n",
    "    {\"name\": \"The Kaaba\", \"location\": \"Mecca, Saudi Arabia\"}\n",
    "]"
   ],
   "id": "77e123ecbf4532ed",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T16:56:54.931477Z",
     "start_time": "2024-06-12T16:56:53.597025Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "import math\n",
    "import base64\n",
    "from transformers import AutoImageProcessor, ResNetForImageClassification\n",
    "from qdrant_client.models import VectorParams, Distance, PointStruct\n",
    "import random\n",
    "\n",
    "class LandmarksMatcher:\n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "        self.train_files = os.listdir(data_path)\n",
    "        self.df_matching = self.create_matching_dataframe()\n",
    "        \n",
    "        self.processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\n",
    "        self.model = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\")\n",
    "        \n",
    "        self.collection_name = 'instagram_data_new'\n",
    "        # self.collection = qdrant_client.create_collection(\n",
    "        #     collection_name=self.collection_name,\n",
    "        #     vectors_config=VectorParams(\n",
    "        #         size=1000,\n",
    "        #         distance=Distance.COSINE\n",
    "        #     ),\n",
    "        # )\n",
    "\n",
    "    def create_matching_dataframe(self):\n",
    "        matching = []\n",
    "        for i, class_name in enumerate(os.listdir(self.data_path)):\n",
    "            class_path = os.path.join(self.data_path, class_name)\n",
    "            for image_name in os.listdir(class_path):\n",
    "                image_path = os.path.join(class_path, image_name)\n",
    "                matching.append({\n",
    "                    'landmark': landmarks[i]['name'],\n",
    "                    'image_path': image_path.replace(\"\\\\\", '/'),\n",
    "                    'Location': landmarks[i]['location'],\n",
    "                    'class': 1,\n",
    "                })\n",
    "        return pd.DataFrame(matching)\n",
    "    \n",
    "    def resize_image(self, image, target_width=256):\n",
    "        image_aspect_ratio = image.size[0] / image.size[1]\n",
    "        resized_img = image.resize(\n",
    "            [target_width, math.floor(target_width * image_aspect_ratio)]\n",
    "        )\n",
    "        return resized_img\n",
    "\n",
    "    def convert_image_to_base64(self, image):\n",
    "        buffered = BytesIO()\n",
    "        image.save(buffered, format=\"JPEG\")\n",
    "        return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "    def upload_item(self, idx):\n",
    "        if idx >= len(self.df_matching):\n",
    "            raise IndexError(\"Index out of range\")\n",
    "\n",
    "        item_data = self.__getitem__(idx)\n",
    "        row = item_data['row']\n",
    "        logits = item_data['logits']\n",
    "        points = [\n",
    "            PointStruct(\n",
    "                id=idx,\n",
    "                payload={\n",
    "                    'landmark': row['landmark'],\n",
    "                    'class': row['class'],\n",
    "                    'image_path': row['image_path'],\n",
    "                    'Location': row['Location'],\n",
    "                    'encoded_image': item_data['encoded_image'],\n",
    "                },\n",
    "                vector=logits.flatten().tolist()\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        print(qdrant_client.upsert(\n",
    "            collection_name=self.collection_name,\n",
    "            points=points\n",
    "        ))\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self.df_matching):\n",
    "            raise IndexError(\"Index out of range\")\n",
    "        \n",
    "        row = self.df_matching.iloc[idx]\n",
    "        image = Image.open(row['image_path'])\n",
    "        image = image.convert('RGB')\n",
    "        image = self.resize_image(image)\n",
    "        encoded_image = self.convert_image_to_base64(image)\n",
    "        \n",
    "        inputs = self.processor(images=image, return_tensors=\"pt\")\n",
    "        outputs = self.model(**inputs)\n",
    "        \n",
    "        return {\n",
    "            'row': row.to_dict(),\n",
    "            'image': image,\n",
    "            'encoded_image': encoded_image,\n",
    "            'logits': outputs.logits\n",
    "        }\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df_matching)\n",
    "        \n",
    "data2_path = '../Data/Photos'\n",
    "matcher2 = LandmarksMatcher(data2_path)"
   ],
   "id": "29628aa884031af0",
   "outputs": [],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
